В 2025 году Google и Apple показали два близких по целям, но разных по устройству стека. В Pixel 10 системный ИИ построен вокруг Android AICore и связки on-device и облака. В iPhone 17 развивают Apple Intelligence, а тяжёлые запросы переносят в Private Cloud Compute.

В статье расскажем, как Pixel 10 и iPhone 17 маршрутизируют ИИ-запросы, что дают Tensor G5 и A19, как устроены Private AI Compute и Private Cloud Compute, где живёт ИИ-слой в ОС — и что всё это меняет для разработчиков, когда ИИ становится частью оболочки, а не отдельной библиотекой.
Вступление

Смартфонный ИИ быстро смещается из «функций внутри приложения» в слой платформы. На первый план выходят три вопроса: где выполняется запрос, какие данные попадают в контекст и кто может увидеть результат. 

Доступность конкретных ИИ-функций почти всегда зависит от языка, региона и модели устройства; часть возможностей может быть недоступна в отдельных странах или языковых конфигурациях. Мы поговорим об архитектуре — границе доверия, маршрутизации и изоляции, но никто не сможет гарантировать, что конкретная функция включится «прямо сейчас» в вашем регионе.
On-device и облако: куда уходит ИИ-запрос

Обе платформы используют гибридную схему: часть задач выполняется на устройстве, часть уходит в облако. Вариант on-device (инференс — расчёт ответа модели по входным данным на самом устройстве) обычно закрывает быстрые сценарии и уменьшает объём данных, покидающих телефон. А облако даёт доступ к более крупным моделям и длинному контексту.

В Android локальный генеративный слой часто связывают с мультимодальной нейросетью Gemini Nano, которая работает в AICore — системном сервисе Android для исполнения и обновления foundation-моделей на устройстве — и опирается на аппаратные ускорители, чтобы снизить задержку и поддерживать актуальность модели. 

На Pixel эта логика проявляется как «системные» жесты и функции поверх любого приложения. Например, Circle to Search работает как жест поверх экрана и позволяет искать по выделенному фрагменту без переключения приложений. Это важно не как «фича конкретной модели», а как пример того, что ИИ становится частью оболочки.

Часть функций Pixel 10 строится вокруг проактивных подсказок. Magic Cue поднимает действия по контексту и работает «на устройстве и в облаке» в изолированной среде.

Когда слоя on-device не хватает, Google подключает Private AI Compute. Это облачная среда для обработки чувствительных запросов, где приватность должна быть техническим свойством исполнения, а не только политикой доступа. Разработчики описывают идею так: данные и результаты обработки должны оставаться доступными только пользователю, а безопасность обеспечивается изоляцией и проверяемостью выполнения. Элементы реализации: 

    стек на собственных ускорителях тензорных операций;

    аппаратные изолированные среды Titanium Intelligence Enclaves;

    удалённая аттестация: проверка, что код выполняется внутри доверенной среды;

    шифрование канала «устройство — облако».

В iPhone 17 технология Apple Intelligence старается решать задачи на устройстве, и для функций, которым нужны более крупные foundation-модели, использует Private Cloud Compute, или PCC. 
Tensor G5 и A19: что именно ускоряет ИИ

Pixel 10 вышел в четырёх вариантах: Pixel 10, Pixel 10 Pro, Pixel 10 Pro XL и Pixel 10 Pro Fold. Базовый уровень производительности в них обеспечивает чипсет Tensor G5, изготовленный по на 3-нм техпроцессу. Этот чипсет — ускоритель тензорных операций — берёт на себя расчёт значительной части инференса: Google утверждает, что он справляется с этим в среднем на 34 % быстрее центрального процессора. То есть разработчики стараются выполнять больше сценариев на смартфоне и реже обращаться к облаку.

У iPhone 17 базовый чип — A19, тоже изготовленный по 3-нм техпроцессу. Он содержит обновлённые блоки display engine и ISP, а также Apple Neural Engine, или NPU, — нейроускоритель для операций машинного обучения, который помогает Apple Intelligence. В каждое GPU-ядро смартфона встроены «нейроускорители» для поддержки работы генеративных моделей.

iPhone 17 Pro и iPhone 17 Pro Max оснащены чипсетом A19 Pro с 16-ядерным Neural Engine, а также 6-ядерным GPU с «нейроускорителями» в каждом из них.

Иными словами, обе компании усиливают локальный контур и добавляют специализированные аппаратные блоки под генеративные модели. При этом точка входа в ОС разная: в Android AICore выделен в отдельный системный слой, а в iOS большая часть логики спрятана в Apple Intelligence и в интеграции системных приложений.
Где проходит граница приватности данных

В мобильном ИИ почти всегда есть три класса данных: вход запроса, контекст устройства и результат. Каждый класс может оставаться на устройстве или уходить в облако. Поэтому важнее не тезис «всё локально», а границы доверия, явная модель угроз и проверяемость механизмов.

В Android развивают Private Compute Core (в материалах Google иногда сокращается как PCC, не путайте с Apple PCC — Private Cloud Compute). Это изолированная среда в ОС для обработки конфиденциальных данных. Она призвана помочь пользователям контролировать, когда и как данные могут покидать границу доверенной зоны. Также в Android существуют Private Compute Services, которые связывают Private Compute Core с облаком и публикуются как отдельный компонент.

В Pixel 10 добавили защищённый сопроцессор Titan M2. В ИИ-сценариях он обеспечивает hardware root of trust — аппаратный источник доверия, поддерживая проверенную загрузку и ключевые операции безопасности. Но выбор между on-device и облаком определяется, скорее, связкой AICore, Private Compute Core и Private AI Compute.

Apple строит приватность вокруг Private Cloud Compute. Компания заявляет о недоступности персональных данных, находящихся в PCC, для кого-либо кроме пользователя, включая саму Apple — при условии корректной работы механизмов изоляции и аттестации. Кроме того, в PCC используется концепция «проверяемой прозрачности», позволяющую проверять сборки PCC и цепочки доверия.

То есть Google переносит часть «модели безопасности устройства» в облако через Private AI Compute, аттестацию и шифрование канала, а Apple переносит модель безопасности устройства в облако через PCC и проверяемые сборки. Это разные реализации одной идеи: если запрос уходит в облако, то граница доверия должна оставаться технической, а не договорной.
Что всё это меняет для разработчика (и почему это важно в финтехе)

Когда ИИ становится слоем ОС, меняется не только набор API, но и «поверхность атаки», особенно там, где приложение обрабатывает персональную информацию, финансовые данные и операции с повышенными требованиями к контролю и аудиту.

Во-первых, «ИИ поверх приложения» перестаёт быть исключением. Жесты на уровне оболочки, например, Circle to Search, позволяют инициировать обработку фрагмента экрана без переключения приложений.

Во-вторых, системные инструменты для работы с текстом и контекстом начинают функционировать там, где пользователь пишет, включая сторонние приложения и сайты. Технология Visual intelligence помогает получать контекст по объектам, местам и тексту вокруг и на экране смартфоне.

В-третьих, «приватное облако» не отменяет вопроса о границах: какие классы данных могут покидать устройство, и на каком уровне это контролируется — платформой и настройками ОС или логикой приложения? На практике это означает, что при проектировании потоков данных приходится учитывать не только собственный бэкенд, но и платформенные ИИ-контуры, а также их региональную/языковую доступность.
Интеграция в ОС: кто управляет моделями

В Android Gemini Nano исполняется в AICore и задействует аппаратные ускорители смартфона. Для мобильных разработчиков это означает, что есть единый вход в «системную модель» вместо множества библиотек и сред исполнения.

Google развивает API ML Kit GenAI, которые работают «поверх AICore», используют Gemini Nano и обеспечивают готовые сценарии работы вроде суммаризации и переписывания текста. Благодаря тому, что приложения используют одну и ту же модель, а запросы изолируются на уровне AICore, достигается экономия памяти.

Apple пошла иным путём. В 2025 году компания открыла разработчикам доступ к работающей на устройстве foundation-модели Apple Intelligence, имеющей около 3 млрд параметров. Apple подчёркивает, что эта модель подходит для текстовых задач и не предназначена для «чат-бота с общими знаниями».
Компромиссы в задержках, контексте и стоимости облака

Контур on-device выигрывает по задержке и автономности, но ограничен размером модели и ресурсами устройства. Облако выигрывает по размеру модели и длине контекста, но добавляет сетевую задержку и ставит вопрос о границах доверенности.

Google описывает Private AI Compute как платформу, предоставляющую все преимущества облачных моделей Gemini с приватностью на уровне выполнения на устройстве и при этом заявляет приватность уровня on-device обработки. На практике это означает, что часть функций получает облачный «усилитель», а данные остаются закрытыми.

В iOS реализован похожий компромисс: Private Cloud Compute подключается для функций, которым нужны более крупные foundation-модели, при этом доступ к данным ограничен и есть возможность внешней проверки. При таком подходе облачный контур требует доверия к заявленной проверяемости.
UX: когда ИИ проявляет инициативу

Различие между iOS и Android чаще всего проявляется не в отдельных кнопках, а в том, когда система проявляет инициативу.

В Pixel 10 сделана ставка на инициативность устройства. Оно реагирует на действия, предлагает варианты, дополняет текст, показывает подсказки до того, как пользователь их запросит. Здесь ИИ не инструмент, а часть логики всей системы — от клавиатуры до галереи. Например, Magic Cue соединяет данные из разных приложений и предлагает пользователю подсказки «когда они нужны». В Google подчёркивают изоляцию данных и контроль со стороны пользователя.

В iPhone 17 ИИ чаще проявляется как встроенная в конкретном месте функция. Заметнее всего это при работе с текстом. Например, при переводе Live Translation работает в качестве системной функции в Почте, Сообщениях, FaceTime и Телефоне, а Writing Tools активны в Почте, Заметках и Сообщениях.
Почему ИИ заметнее всего в работе камеры

Камера стала удобной площадкой для сравнения ИИ-подходов обеих компаний, потому что здесь самые жёсткие требования по задержке, качеству работы, энергопотреблению и приватности.

Pixel 10 превращает камеру в продолжение ИИ. С помощью Camera Coach, Face Unblur и Auto Best Take система делает серию снимков и сама выбирает лучший кадр. Camera Coach использует модели Gemini и просит подключение к сети, потому что часть подсказок опирается на облачные модели. Например, система может подсказать идеальные параметры для снимков при слабом освещении. Best Take собирает групповые фото из нескольких похожих кадров, чтобы все выглядели удачно

В iPhone 17 сделали ставку на конвейерную обработку. Камера Dual Fusion на 48 МП обрабатывает снимки аккуратно и почти незаметно. ИИ не вмешивается в кадр, а лишь помогает передать естественные цвета и детали. В моделях Pro оптический зум увеличили до 8-кратного, и при конвейерной обработке используется больше машинного обучения, чтобы сохранить детали, снизить шум и улучшить цвет .

Здесь разница не сводится к «лучше или хуже». У Pixel часть функций выглядит как подсказка и помощь до снимка. У iPhone часть логики уходит в вычислительную фотографию и проявляется уже в результате.
Позиция Apple и Google в мобильном ИИ к началу 2026 года

В январе 2026 года Apple и Google выпустили совместное заявление о многолетнем сотрудничестве: следующая версия Apple Foundation Models должна опираться на модели Gemini и облачную технологию Google, чтобы поддержать будущие функции Apple Intelligence и более персональную Siri.

Google в ноябре 2025 года открыла Private AI Compute как платформу для облачных моделей с приватными границами, и в качестве одного из первых примеров назвала развитие Magic Cue на Pixel.

То есть к началу 2026 года обе компании пришли к одной концепции: слой on-device остаётся базовым, а облако добавляет более сильные модели. Критичными становятся границы доверенности, аттестация и проверяемость.